{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The purpose of this notebook is to do some 'pre-cleaning' of the data, so we have a training and test set that is ready to be further cleaned and analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import presetup\n",
    "import seaborn as sns\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.cross_validation import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/raw/raw_data.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['entry_id' 'field_id_4' 'field_id_8' 'field_id_13' 'field_id_15'\n",
      " 'field_id_17' 'field_id_18' 'field_id_19' 'field_id_20' 'field_id_21'\n",
      " 'field_id_23' 'field_id_25' 'field_id_27' 'field_id_28' 'field_id_29'\n",
      " 'field_id_33' 'field_id_40' 'field_id_41' 'field_id_42' 'field_id_68'\n",
      " 'field_id_70' 'field_id_71' 'field_id_72' 'field_id_73' 'field_id_74'\n",
      " 'field_id_75' 'field_id_89' 'field_id_96' 'field_id_98' 'field_id_100'\n",
      " 'field_id_101' 'field_id_104' 'field_id_105' 'field_id_106' 'field_id_107'\n",
      " 'field_id_108' 'field_id_111' 'field_id_112' 'field_id_113' 'field_id_114'\n",
      " 'field_id_115' 'field_id_116' 'field_id_117' 'field_id_118' 'field_id_119'\n",
      " 'field_id_120' 'field_id_121' 'field_id_122' 'field_id_123' 'field_id_124'\n",
      " 'field_id_125' 'field_id_126' 'field_id_127' 'field_id_176' 'field_id_250'\n",
      " 'field_id_252' 'field_id_264' 'field_id_329' 'field_id_330' 'field_id_331'\n",
      " 'field_id_394' 'field_id_395' 'field_id_410' 'field_id_411' 'field_id_412'\n",
      " 'field_id_413' 'field_id_414' 'field_id_426' 'field_id_434' 'field_id_435'\n",
      " 'field_id_440' 'field_id_441' 'field_id_442']\n"
     ]
    }
   ],
   "source": [
    "print df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's instantiate an instance of the PreSetup class from our custom module 'presetup' - we'll use it to fetch a list of interpretable column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ps = presetup.PreSetup()\n",
    "col_dict = ps.parseCols('../data/reference/column_names.txt')\n",
    "df.columns = ps.updateCols(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id' 'Gender' 'Undergraduate Schools Attended'\n",
      " 'Undergraduate Graduation Year' 'Undergraduate Major(s)' 'Ethnicity'\n",
      " 'Home State or Territory (US)' 'Home City' 'High School Type'\n",
      " 'High School GPA' 'High School Class Rank'\n",
      " 'High School AP / IB Classes and Scores' 'Undergraduate Additional Info'\n",
      " 'High School Extracurricular Activities' 'High School Sports Played'\n",
      " 'High School Other Honors and Awards' 'Undergraduate Acceptance'\n",
      " 'Undergraduate Month Applied' 'Undergraduate Schools Applied'\n",
      " 'Who are you?' 'About Me' 'Birth Year' 'Home Country'\n",
      " 'Is English your first language?' 'Do you speak other languages?'\n",
      " 'Undergrad Legacy' 'Undergraduate Degree Type'\n",
      " 'Undergraduate Type of Major(s)' 'Highest SAT Scores'\n",
      " 'How many times did you take the official SAT?'\n",
      " 'SAT 2 Tests Taken and Highest Scores'\n",
      " 'Undergraduate Personal Statement Topic'\n",
      " 'Undergraduate Personal Statement Type' 'Undergraduate Personal Statement'\n",
      " 'Undergraduate Supplemental Essay'\n",
      " 'How did you spend your summers during high school?' 'Other SAT Scores'\n",
      " 'What SAT test prep did you use?' 'Highest ACT Scores' 'Other ACT Scores'\n",
      " 'How many times did you take the ACT?' 'What ACT test prep did you use?'\n",
      " 'PSAT Scores' 'Other Standardized Tests Taken In High School'\n",
      " 'College Classes in High School' 'Academic Performance in High School'\n",
      " 'Low Grades in High School' 'High School Work & Volunteer Experience'\n",
      " 'Undergraduate Application Additional Materials'\n",
      " 'Undergraduate Essay Details'\n",
      " 'Elaborate on High School Extracurricular or Work'\n",
      " 'Undergraduate Number of Schools Applied' 'Undergraduate Advice'\n",
      " 'Internal Use - Calculated Undergrad Price'\n",
      " 'Number of Advanced Placement (AP) Tests Taken'\n",
      " 'Undergrad Verification Documents' 'Highest Composite SAT Score'\n",
      " 'TOEFL iBT' 'TOEFL PBT' 'List your private college consultant(s), if any'\n",
      " \"Undergrad Student's Grad School Interests\"\n",
      " \"Undergrad Student's Grad School Other\" 'Nationality'\n",
      " 'No major in the list' 'No other languages'\n",
      " 'Did either of your parents attend college in the U'\n",
      " 'Five adjectives College' \"Undergrad Student's Grad School Interests NEW\"\n",
      " 'ZIP / Postal Code' 'Home State / Province (Outside U.S.)'\n",
      " 'NEW Personal Statement' 'GPA Scale' 'School Type CEEB']\n"
     ]
    }
   ],
   "source": [
    "print df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Admit Creating College / Grad School Profile    18465\n",
       "Student Applying To College / Grad School         102\n",
       "Other Professional                                 32\n",
       "School Faculty / Professional                      12\n",
       "Parent                                              7\n",
       "Name: Who are you?, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Who are you?'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're only interested in the profiles of those who have gone through the college admissions process and are not school faculty or parents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df[df['Who are you?']=='Admit Creating College / Grad School Profile'].copy()\n",
    "df.reset_index(inplace=True)\n",
    "df.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some more housekeeping: let's replace the base64 nulls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vals = ['YTowOnt9', 'ytowont9', 'czowOiIiOw==']\n",
    "for v in vals:\n",
    "    df.replace(to_replace=v, value=np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Target Variable: Acceptance into a Top School"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "1. Instantiate a new instance of the Schools class.\n",
    "2. Get list of all schools.\n",
    "3. Create a new DataFrame df_schools, where cols are schools, rows are students\n",
    "4. Update acceptance status for each school in df_schools.\n",
    "5. Create a separate DataFrame df_topschools (where the cols are just the 'top schools').\n",
    "6. Convert each col into binary (1 for accepted, 0 for not), then create new col called any_top_school to indicate acceptance into any top school.\n",
    "7. Join back with main df, and make any necessary adjustments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1\n",
    "Instantiate a new instance of the Schools class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc = presetup.Schools()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2\n",
    "Get list of all schools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_schools = sc.getSchools('../data/reference/table_references.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1355 1353\n"
     ]
    }
   ],
   "source": [
    "print len(all_schools), len(set(all_schools))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few duplicates- let's remove these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_schools = list(set(all_schools))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3\n",
    "Create a new DataFrame df_schools, where cols are schools, rows are students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_schools = pd.DataFrame(index=xrange(len(df)), columns=all_schools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4\n",
    "Update acceptance status for each school in df_schools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc.extractFromApplied(df['Undergraduate Schools Applied'], df_schools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to some formatting hiccups in the data, a handful of non-school columns were generated. Let's get rid of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_schools = df_schools[all_schools]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5\n",
    "Create a separate DataFrame df_topschools (where the cols are just the 'top schools')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_schools = ['Harvard University (Cambridge, MA)', 'Yale University (New Haven, CT)', \n",
    "               'Cornell University (Ithaca, NY)', 'Columbia University (New York, NY)',\n",
    "               'University of Pennsylvania (Philadelphia, PA)', 'Princeton University (Princeton, NJ)',\n",
    "               'Brown University (Providence, RI)', 'Dartmouth College (Hanover, NH)',\n",
    "               'Massachusetts Institute of Technology (Cambridge, MA)','Stanford University (Stanford, CA)']\n",
    "df_topschools = df_schools[top_schools].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6\n",
    "Convert each col into binary (1 for accepted, 0 for not), then create new col called any_top_school to indicate acceptance into any top school."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for school in top_schools:\n",
    "    df_topschools[school] = df_topschools[school].apply(lambda x: sc.cleanFromApplied(x) if type(x) == str else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_topschools['any_top_school'] = (df_topschools.sum(axis=1)).apply(lambda x: 1 if x>0 else np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7\n",
    "Join back with main df, and make any necessary adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Join df_topschools back with main df\n",
    "df = df.join(df_topschools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6614\n",
      "17639\n"
     ]
    }
   ],
   "source": [
    "print df['Undergraduate Schools Applied'].notnull().sum()\n",
    "print df['Undergraduate Schools Attended'].notnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's another problem here- we just extracted info out of the 'Undergraduate Schools Applied' column, but it has far more null values than 'Undergraduate Schools Attended', which means we're currently missing out on a lot of potentially important data. Let's cover our bases by incorporating the data in the Attended column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['any_top_school_v2'] =  df['Undergraduate Schools Attended'].apply(sc.extractFromAttended)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's combine the data from the two columns to get top_school_final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['top_school_final'] = df.apply(sc.finalTopSchool, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in that process, we have made an implicit assumption that those who did not apply to a top school would not have gotten in anyway. While it may not be the most robust approach, we assume that students that actually have a fair chance of getting into a top school would have applied anyway, and that result is reflected in our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Rows that are Too Sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over-sparseness is a huge problem in this data set. Fortunately, AdmitSee has already internally created a function to determine the 'usefulness' (how much is filled) of each profile, indicated by the 'Internal Use - Calculated Undergrad Price'. As suggested by their Founding Engineer, let's only keep those > 4 for this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = df[df['Internal Use - Calculated Undergrad Price']>4].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4416\n",
      "1    1657\n",
      "Name: top_school_final, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "target_distr = df2['top_school_final'].value_counts()\n",
    "print target_distr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.727153\n",
      "1    0.272847\n",
      "Name: top_school_final, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print target_distr/float(sum(target_distr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great- our task is now done. We have about a quarter of students who got into a top school."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final step in this pre-setup, let's do a 70-30 train test split, and export the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, train_size=0.7, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train.to_csv('../data/train.csv')\n",
    "df_test.to_csv('../data/test.csv')\n",
    "df.to_csv('../data/master.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
